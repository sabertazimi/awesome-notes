"use strict";(self.webpackChunknotes=self.webpackChunknotes||[]).push([[93486],{47552:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"ai/gen/recipes/code/langchain","title":"LangChain","description":"Model I/O","source":"@site/content/ai/gen/recipes/code/langchain.md","sourceDirName":"ai/gen/recipes/code","slug":"/ai/gen/recipes/code/langchain","permalink":"/notes/ai/gen/recipes/code/langchain","draft":false,"unlisted":false,"editUrl":"https://github.com/sabertazimi/notes/edit/main/content/ai/gen/recipes/code/langchain.md","tags":[],"version":"current","lastUpdatedBy":"Sabertaz","lastUpdatedAt":1769518084000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Claude Code","permalink":"/notes/ai/gen/claude"},"next":{"title":"NanoCode","permalink":"/notes/ai/gen/recipes/code/nanocode"}}');var a=t(35656),o=t(86145);const i={},s="LangChain",c={},l=[{value:"Model I/O",id:"model-io",level:2},{value:"Retrieval",id:"retrieval",level:2},{value:"Chains",id:"chains",level:2},{value:"Agents",id:"agents",level:2},{value:"Retrieval-Augmented Generation",id:"retrieval-augmented-generation",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",pre:"pre",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"langchain",children:"LangChain"})}),"\n",(0,a.jsx)(n.h2,{id:"model-io",children:"Model I/O"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import { CommaSeparatedListOutputParser } from '@langchain/core/output_parsers'\nimport { PromptTemplate } from '@langchain/core/prompts'\nimport { OpenAI } from '@langchain/openai'\n\nconst template = PromptTemplate.fromTemplate('List 10 {subject}.\\n{format_instructions}')\nconst model = new OpenAI({ temperature: 0 })\nconst listParser = new CommaSeparatedListOutputParser()\n\nconst prompt = await template.format({\n  subject: 'countries',\n  format_instructions: listParser.getFormatInstructions(),\n})\n\nconst result = await model.invoke(prompt)\nconst listResult = await listParser.parse(result)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"retrieval",children:"Retrieval"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import { UpstashVectorStore } from '@langchain/community/vectorstores/upstash'\nimport { OpenAIEmbeddings } from '@langchain/openai'\nimport { CSVLoader } from 'langchain/document_loaders/fs/csv'\nimport { ScoreThresholdRetriever } from 'langchain/retrievers/score_threshold'\nimport { RecursiveCharacterTextSplitter } from 'langchain/text_splitter'\n\n// CSV data.\nconst loader = new CSVLoader('path/to/example.csv')\nconst docs = await loader.load()\n\n// Text splitter.\nconst splitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 10,\n  chunkOverlap: 1,\n})\nconst docs = await splitter.createDocuments(['...'])\n\n// Embeddings and vector store.\nconst vectorStore = new UpstashVectorStore(new OpenAIEmbeddings())\nawait vectorStore.addDocuments(docs)\nconst retriever = ScoreThresholdRetriever.fromVectorStore(vectorStore, {\n  minSimilarityScore: 0.9,\n})\nconst result = await retriever.getRelevantDocuments('...?')\n"})}),"\n",(0,a.jsx)(n.h2,{id:"chains",children:"Chains"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import { CommaSeparatedListOutputParser } from '@langchain/core/output_parsers'\nimport { PromptTemplate } from '@langchain/core/prompts'\nimport { RunnableSequence } from '@langchain/core/runnables'\nimport { OpenAI } from '@langchain/openai'\n\nconst template = PromptTemplate.fromTemplate('List 10 {subject}.\\n{format_instructions}')\nconst model = new OpenAI({ temperature: 0 })\nconst listParser = new CommaSeparatedListOutputParser()\n\nconst chain = RunnableSequence.from([template, model, listParser])\n\nconst result = await chain.invoke({\n  subject: 'countries',\n  format_instructions: listParser.getFormatInstructions(),\n})\n"})}),"\n",(0,a.jsx)(n.h2,{id:"agents",children:"Agents"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import { createVectorStoreAgent, VectorStoreToolkit } from 'langchain/agents'\n\nconst toolkit = new VectorStoreToolkit({ name: 'Demo Data', vectorStore }, model)\nconst agent = createVectorStoreAgent(model, toolkit)\n\nconst result = await agent.invoke({ input: '...' })\n"})}),"\n",(0,a.jsx)(n.h2,{id:"retrieval-augmented-generation",children:"Retrieval-Augmented Generation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from langchain_community.document_loaders import PyPDFLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.embeddings import HuggingFaceBgeEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom google.colab import userdata\n\n# Load document\ndocument_url = "https://arxiv.org/pdf/2312.10997.pdf"\nloader = PyPDFLoader(document_url)\npages = loader.load()\n\n# Split document into chunks\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=400,\n    chunk_overlap=40,\n    length_function=len,\n    is_separator_regex=False,\n)\nchunks = text_splitter.split_documents(pages)\n\n# Create embeddings from chunks\nmodel_name = "BAAI/bge-small-en"\nmodel_kwargs = {"device": "cpu"}\nencode_kwargs = {"normalize_embeddings": True}\nbge_embeddings = HuggingFaceBgeEmbeddings(\n    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n)\n\nchunk_texts = list(map(lambda d: d.page_content, chunks))\nembeddings = bge_embeddings.embed_documents(chunk_texts)\n\n# Store embeddings\ntext_embedding_pairs = zip(chunk_texts, embeddings)\ndb = FAISS.from_embeddings(text_embedding_pairs, bge_embeddings)\n\n# Search database for similar contexts\nquery = "Which are the drawbacks of Naive RAG?"\n\ncontexts = db.similarity_search(query, k=5)\n\n# Chat with model\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            "system",\n            """You are an expert at answering questions\n            based on a context extracted from a document.\n            The context extracted from the document is: {context}""",\n        ),\n        ("human", "{question}"),\n    ]\n)\n\napi_key = userdata.get("ANTHROPIC_API_KEY")\nmodel = ChatAnthropic(model="claude-3-haiku-20240307", api_key=api_key)\n\nchain = prompt | model\n\nresponse = chain.invoke(\n    {\n        "context": "\\n\\n".join(list(map(lambda c: c.page_content, contexts))),\n        "question": query,\n    }\n)\n\nprint(response.content)\n'})})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},86145:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>s});var r=t(57140);const a={},o=r.createContext(a);function i(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);